{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d0695b2-f51d-48d3-942d-8a0e9206edc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import (OneHotEncoder, StandardScaler, LabelBinarizer)\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, confusion_matrix, classification_report,\n",
    "    roc_auc_score, roc_curve\n",
    ")\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "410f3ab2-59b3-4e94-b540-3a4e73fc5261",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"credit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df2f7742-c116-4ed0-8e78-616230ce2173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define Target and Features\n",
    "# ============================================\n",
    "y = df[\"default\"]\n",
    "X = df.drop(\"default\", axis=1)\n",
    "\n",
    "numeric_features = [\"months_loan_duration\", \"amount\", \"percent_of_income\", \n",
    "                    \"years_at_residence\", \"age\", \"existing_loans_count\", \"dependents\"]\n",
    "\n",
    "categorical_features = [\"checking_balance\", \"credit_history\", \"purpose\", \n",
    "                        \"savings_balance\", \"employment_duration\", \n",
    "                        \"other_credit\", \"housing\", \"job\", \"phone\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a0edd4a-4e3a-48ef-858a-d9120d1b3ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Preprocessing\n",
    "# ============================================\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numeric_features),\n",
    "        (\"cat\", OneHotEncoder(drop=\"first\"), categorical_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b9a9d61-bcc4-4a95-9597-4a01874becc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Model Pipelines\n",
    "# ============================================\n",
    "log_reg_pipe = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "tree_pipe = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", DecisionTreeClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "forest_pipe = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", RandomForestClassifier(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df7a573f-eef5-4b0f-8007-800141517918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Parameter Grids\n",
    "# ============================================\n",
    "param_grid_log_reg = {\n",
    "    \"classifier__C\": [0.01, 0.1, 1, 10],\n",
    "    \"classifier__solver\": [\"lbfgs\", \"liblinear\"]\n",
    "}\n",
    "\n",
    "param_grid_tree = {\n",
    "    \"classifier__max_depth\": [3, 5, 7, 10, None],\n",
    "    \"classifier__min_samples_split\": [2, 5, 10],\n",
    "    \"classifier__criterion\": [\"gini\", \"entropy\"]\n",
    "}\n",
    "\n",
    "param_grid_forest = {\n",
    "    \"classifier__n_estimators\": [50, 100, 200],\n",
    "    \"classifier__max_depth\": [5, 8, 10, None],\n",
    "    \"classifier__min_samples_split\": [2, 5, 10],\n",
    "    \"classifier__criterion\": [\"gini\", \"entropy\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac2caa4d-d634-4bdd-bacd-5281830495bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Train-Test Split\n",
    "# ============================================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f39b5fc-3e00-4990-b2b3-b6b3566a625a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Tuning Logistic Regression ...\n",
      "Best CV Score: 0.7387\n",
      "Best Parameters: {'classifier__C': 10, 'classifier__solver': 'liblinear'}\n",
      "\n",
      "ðŸ” Tuning Decision Tree ...\n",
      "Best CV Score: 0.7025\n",
      "Best Parameters: {'classifier__criterion': 'gini', 'classifier__max_depth': 3, 'classifier__min_samples_split': 2}\n",
      "\n",
      "ðŸ” Tuning Random Forest ...\n",
      "Best CV Score: 0.7525\n",
      "Best Parameters: {'classifier__criterion': 'gini', 'classifier__max_depth': None, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# 6. GridSearchCV (5-fold CV)\n",
    "# ============================================\n",
    "models = {\n",
    "    \"Logistic Regression\": (log_reg_pipe, param_grid_log_reg),\n",
    "    \"Decision Tree\": (tree_pipe, param_grid_tree),\n",
    "    \"Random Forest\": (forest_pipe, param_grid_forest)\n",
    "}\n",
    "\n",
    "best_models = {}\n",
    "results_summary = []\n",
    "\n",
    "for name, (pipe, params) in models.items():\n",
    "    print(f\"\\nðŸ” Tuning {name} ...\")\n",
    "    grid = GridSearchCV(pipe, params, cv=5, n_jobs=-1, scoring=\"accuracy\")\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    best_models[name] = grid.best_estimator_\n",
    "    best_score = grid.best_score_\n",
    "    best_params = grid.best_params_\n",
    "    \n",
    "    print(f\"Best CV Score: {best_score:.4f}\")\n",
    "    print(f\"Best Parameters: {best_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "15d1a980-235e-4076-b826-b92ebddf1fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Logistic Regression Evaluation ===\n",
      "Accuracy: 0.75\n",
      "AUC: 0.7693\n",
      "Confusion Matrix:\n",
      " [[121  19]\n",
      " [ 31  29]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          no       0.80      0.86      0.83       140\n",
      "         yes       0.60      0.48      0.54        60\n",
      "\n",
      "    accuracy                           0.75       200\n",
      "   macro avg       0.70      0.67      0.68       200\n",
      "weighted avg       0.74      0.75      0.74       200\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'LabelBinarizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 28\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfusion Matrix:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, confusion_matrix(y_test, y_pred))\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification Report:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, classification_report(y_test, y_pred))\n\u001b[1;32m---> 28\u001b[0m lb \u001b[38;5;241m=\u001b[39m LabelBinarizer()\n\u001b[0;32m     29\u001b[0m y_test_bin \u001b[38;5;241m=\u001b[39m lb\u001b[38;5;241m.\u001b[39mfit_transform(y_test)\u001b[38;5;241m.\u001b[39mravel()\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Plot ROC curve\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LabelBinarizer' is not defined"
     ]
    }
   ],
   "source": [
    "# 7. Evaluation on Test Set (Accuracy + AUC)\n",
    "# ============================================\n",
    "# plt.figure(figsize=(8, 6))\n",
    "for name, model in best_models.items():\n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "    \n",
    "    # Metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_prob) if y_prob is not None else np.nan\n",
    "    \n",
    "    # Save results\n",
    "    results_summary.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": acc,\n",
    "        \"AUC\": auc\n",
    "    })\n",
    "    \n",
    "    # Print detailed report\n",
    "    print(f\"\\n=== {name} Evaluation ===\")\n",
    "    print(\"Accuracy:\", round(acc, 4))\n",
    "    print(\"AUC:\", round(auc, 4))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    y_test_bin = lb.fit_transform(y_test).ravel()\n",
    "\n",
    "    \n",
    "    # Plot ROC curve\n",
    "    if y_prob is not None:\n",
    "        fpr, tpr, _ = roc_curve(y_test_bin, y_prob)\n",
    "        plt.plot(fpr, tpr, label=f\"{name} (AUC = {auc:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "769bf255-24b9-40cf-93ae-0c934d3bb1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique classes in y_test: ['no' 'yes']\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique classes in y_test:\", np.unique(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d1ef360-af0f-4212-ae67-1532c16141c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Model Comparison Summary ===\n",
      "                 Model  Accuracy       AUC\n",
      "0        Random Forest     0.765  0.797262\n",
      "1        Random Forest     0.765  0.797262\n",
      "2  Logistic Regression     0.750  0.769286\n",
      "3  Logistic Regression     0.750  0.769286\n",
      "4        Decision Tree     0.685  0.715357\n",
      "5        Decision Tree     0.685  0.715357\n"
     ]
    }
   ],
   "source": [
    "# 9. Model Comparison Table\n",
    "# ============================================\n",
    "results_df = pd.DataFrame(results_summary).sort_values(by=\"Accuracy\", ascending=False)\n",
    "print(\"\\n=== Model Comparison Summary ===\")\n",
    "print(results_df.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c170d3-8dc1-439b-a1cb-6e86f2af0d24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
